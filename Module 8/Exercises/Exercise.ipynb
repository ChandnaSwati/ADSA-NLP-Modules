{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Module 8: From Classical to Deep NLP\n",
    "# LSTM Critical Thinking & Application Lab\n",
    "# ============================================\n",
    "# Author: Prof. Dr. Swati Chandna\n",
    "# Course: M.Sc. Applied Data Science & AI\n",
    "# --------------------------------------------\n",
    "# Learning Goals:\n",
    "# - Understand how LSTMs differ from RNNs\n",
    "# - Train & interpret an LSTM on sequential data\n",
    "# - Develop critical reasoning about model behavior\n",
    "# ============================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Fix random seed for reproducibility\n",
    "torch.manual_seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --------------------------------------------\n",
    "# 1. Predict Before You Run\n",
    "# --------------------------------------------\n",
    "# Task:\n",
    "# 1. Predict the input and output shapes for each layer of the LSTM.\n",
    "# 2. Which part of the sequence will influence the final prediction?\n",
    "# 3. Sketch or describe what you expect the loss curve to look like.\n",
    "\n",
    "class DemoLSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size=1, hidden_size=128, batch_first=True)\n",
    "        self.fc = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, (h, c) = self.lstm(x)\n",
    "        return self.fc(out[:, -1, :])\n",
    "\n",
    "model = DemoLSTM()\n",
    "print(model)\n",
    "\n",
    "# Q1: Write your predictions for shapes and sequence influence below.\n",
    "# (Use markdown cells to explain your reasoning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --------------------------------------------\n",
    "#  2. Data Preparation\n",
    "# --------------------------------------------\n",
    "# Generate a synthetic dataset with 200 sequences, each 100 steps long.\n",
    "# The label depends on the first element (requires long-term memory).\n",
    "\n",
    "n_samples = 200\n",
    "seq_len = 100\n",
    "X = torch.rand(n_samples, seq_len, 1)\n",
    "y = (X[:, 0, 0] > 0.5).float()\n",
    "\n",
    "dataset = TensorDataset(X, y)\n",
    "loader = DataLoader(dataset, batch_size=16, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --------------------------------------------\n",
    "# 3. Model Training\n",
    "# --------------------------------------------\n",
    "# Train the DemoLSTM model and observe the loss trend.\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "loss_history = []\n",
    "for epoch in range(10):\n",
    "    total_loss = 0\n",
    "    for batch_x, batch_y in loader:\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(batch_x)\n",
    "        batch_y = batch_y.view(-1, 1)\n",
    "        loss = criterion(preds, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    avg_loss = total_loss / len(loader)\n",
    "    loss_history.append(avg_loss)\n",
    "    print(f\"Epoch {epoch+1} | Loss: {avg_loss:.4f}\")\n",
    "\n",
    "plt.plot(loss_history, marker='o', color='purple')\n",
    "plt.title(\"LSTM Training Loss Curve\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "#  Q2: If accuracy is low, what might be the causes?\n",
    "#  Q3: Which hyperparameter would you adjust first and why?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --------------------------------------------\n",
    "# 4. Compare Architectures\n",
    "# --------------------------------------------\n",
    "# Implement RNN and FFNN for comparison.\n",
    "\n",
    "class FFNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(100, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "class SimpleRNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.RNN(1, 64, batch_first=True)\n",
    "        self.fc = nn.Linear(64, 1)\n",
    "    def forward(self, x):\n",
    "        out, _ = self.rnn(x)\n",
    "        return self.fc(out[:, -1, :])\n",
    "\n",
    "#  Q4: Train both models (FFNN, RNN) on the same dataset and compare.\n",
    "#  Q5: Which model performs best and why?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --------------------------------------------\n",
    "#  5. What-If Experiments\n",
    "# --------------------------------------------\n",
    "# Predict how each change might affect results.\n",
    "# Fill in this table in your notes.\n",
    "\n",
    "# | Modification | Your Prediction | Verified Outcome |\n",
    "# |---------------|----------------|------------------|\n",
    "# | hidden_dim 64 â†’ 256 | | |\n",
    "# | dropout = 0.5 | | |\n",
    "# | Double seq_len | | |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
