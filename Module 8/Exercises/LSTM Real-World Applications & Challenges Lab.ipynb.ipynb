{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# LSTM Real-World Applications & Challenges Lab\n",
    "# ============================================\n",
    "# This notebook focuses on practical, real-world LSTM problems beyond synthetic data.\n",
    "# Each section presents a domain, dataset idea, and hands-on challenge.\n",
    "# ============================================\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --------------------------------------------\n",
    "# 1. Stock Price Prediction (Time Series)\n",
    "# --------------------------------------------\n",
    "# Goal: Predict the next-day closing price based on the last 20 days of data.\n",
    "# Dataset idea: Use Yahoo Finance or synthetic sine waves to simulate price trends.\n",
    "\n",
    "# Generate synthetic sine wave stock data\n",
    "x = np.linspace(0, 200, 2000)\n",
    "prices = np.sin(x / 5) + np.random.normal(scale=0.2, size=len(x))\n",
    "\n",
    "seq_len = 20\n",
    "X, y = [], []\n",
    "for i in range(len(prices) - seq_len):\n",
    "    X.append(prices[i:i+seq_len])\n",
    "    y.append(prices[i+seq_len])\n",
    "\n",
    "X = torch.tensor(X, dtype=torch.float32).unsqueeze(-1)\n",
    "y = torch.tensor(y, dtype=torch.float32).unsqueeze(-1)\n",
    "\n",
    "dataset = TensorDataset(X, y)\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "class StockLSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(1, 64, batch_first=True)\n",
    "        self.fc = nn.Linear(64, 1)\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        return self.fc(out[:, -1, :])\n",
    "\n",
    "model = StockLSTM()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "losses = []\n",
    "for epoch in range(10):\n",
    "    total_loss = 0\n",
    "    for bx, by in loader:\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(bx)\n",
    "        loss = criterion(preds, by)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    losses.append(total_loss / len(loader))\n",
    "    print(f\"Epoch {epoch+1}: Loss {total_loss / len(loader):.4f}\")\n",
    "\n",
    "plt.plot(losses, marker='o')\n",
    "plt.title('Stock Prediction Loss Curve')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n",
    "\n",
    "# Q1: How stable is the loss curve? Does the model capture periodicity?\n",
    "# Q2: Plot predicted vs. true prices and comment on overfitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --------------------------------------------\n",
    "# 2. Sentiment Analysis on Movie Reviews\n",
    "# --------------------------------------------\n",
    "# Task: Train an LSTM to classify short text as positive or negative.\n",
    "# Dataset: IMDb or synthetic text pairs.\n",
    "\n",
    "sample_texts = [\n",
    "    (\"I loved the movie, it was fantastic!\", 1),\n",
    "    (\"Terrible film, I hated every minute.\", 0),\n",
    "    (\"The plot was okay but acting was bad.\", 0),\n",
    "    (\"Absolutely brilliant performance!\", 1)\n",
    "]\n",
    "\n",
    "# Exercise:\n",
    "# 1️. Tokenize and convert words to integers.\n",
    "# 2️. Pad sequences.\n",
    "# 3️. Implement nn.Embedding + nn.LSTM + nn.Linear.\n",
    "# 4️. Train and test on these samples.\n",
    "# 5️. Predict sentiment for your own sentence.\n",
    "\n",
    "#  Q3: How does vocabulary size impact model performance?\n",
    "#  Q4: Test negations like \"not good\" or \"wasn't bad\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --------------------------------------------\n",
    "# 3. Energy Consumption Forecasting\n",
    "# --------------------------------------------\n",
    "# Domain: Smart grid / IoT data.\n",
    "# Task: Predict next-hour energy use from past 24 hours.\n",
    "\n",
    "energy_data = np.sin(np.arange(0, 300, 0.1)) + np.random.normal(scale=0.1, size=3000)\n",
    "seq_len = 24\n",
    "X, y = [], []\n",
    "for i in range(len(energy_data) - seq_len):\n",
    "    X.append(energy_data[i:i+seq_len])\n",
    "    y.append(energy_data[i+seq_len])\n",
    "\n",
    "X = torch.tensor(X, dtype=torch.float32).unsqueeze(-1)\n",
    "y = torch.tensor(y, dtype=torch.float32).unsqueeze(-1)\n",
    "\n",
    "dataset = TensorDataset(X, y)\n",
    "loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "model_energy = StockLSTM()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model_energy.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(5):\n",
    "    for bx, by in loader:\n",
    "        optimizer.zero_grad()\n",
    "        preds = model_energy(bx)\n",
    "        loss = criterion(preds, by)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {epoch+1}: Loss={loss.item():.4f}\")\n",
    "\n",
    "# Q5: How can LSTMs be adapted for multivariate time series (e.g., weather + load)?\n",
    "# Q6: How would you evaluate forecast accuracy beyond loss (e.g., RMSE, MAE)?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --------------------------------------------\n",
    "# 4. Water Quality Prediction (Environmental Application)\n",
    "# --------------------------------------------\n",
    "# Context: Predict next-day Chlorophyll-a concentration based on past 10 days of data.\n",
    "# Data can include variables like temperature, turbidity, rainfall, and pH.\n",
    "\n",
    "# Exercise idea:\n",
    "# - Create a DataFrame with synthetic features (temp, pH, turbidity, chla)\n",
    "# - Train an LSTM to predict future chla values.\n",
    "# - Visualize predicted vs. true curves.\n",
    "\n",
    "# ✏️ Q7: How can feature scaling affect model learning?\n",
    "# ✏️ Q8: Discuss how missing data or sensor noise could impact LSTM accuracy.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
