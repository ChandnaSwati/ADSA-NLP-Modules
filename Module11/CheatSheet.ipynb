{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AI Agent & Model Cheatsheet (Interactive Notebook)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Agent Type Overview\n",
    "\n",
    "| Agent Type | Purpose | Key Actions | Typical Use Case |\n",
    "|-------------|----------|--------------|------------------|\n",
    "| **Retrieval Agent (RAG)** | Gathers information and summarizes | `search()`, `summarize()` | â€œSummarize renewable energy policy in Germany.â€ |\n",
    "| **Analyst Agent** | Evaluates or classifies content | `analyze()`, `compare()` | â€œWhatâ€™s the sentiment of AI news?â€ |\n",
    "| **Decision Agent** | Draws a conclusion or makes a recommendation | `decide()`, `recommend()` | â€œWhich technology should we invest in?â€ |\n",
    "| **Support Agent** | Understands intent and responds | `classify_intent()`, `reply()` | â€œHandle a customer complaint.â€ |\n",
    "| **Fact-Checker Agent** | Validates truth or accuracy | `search()`, `verify()` | â€œDid solar surpass coal in Germany 2023?â€ |\n",
    "| **Collaborative Agent Team** | Multiple agents with roles | `plan()`, `delegate()`, `review()` | â€œResearcher + Critic + Writer teamwork.â€ |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  2. Choosing the Right Model\n",
    "Below are the most common **transformers pipelines** and their use cases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### ğŸ“‹ Common Model Choices\n",
       "- **Summarization** â†’ `facebook/bart-large-cnn`  â€”  _Summarize or condense text._\n",
       "- **Sentiment Analysis** â†’ `distilbert/distilbert-base-uncased-finetuned-sst-2-english`  â€”  _Detect emotional tone._\n",
       "- **Zero-Shot Classification** â†’ `facebook/bart-large-mnli`  â€”  _Classify without training labels._\n",
       "- **Question Answering** â†’ `deepset/roberta-base-squad2`  â€”  _Extract factual answers from context._\n",
       "- **NER** â†’ `dslim/bert-base-NER`  â€”  _Identify names, places, organizations._\n",
       "- **Text Generation** â†’ `google/flan-t5-base`  â€”  _Generate or reason in natural language._"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "models = {\n",
    "    \"Summarization\": (\"facebook/bart-large-cnn\", \"Summarize or condense text.\"),\n",
    "    \"Sentiment Analysis\": (\"distilbert/distilbert-base-uncased-finetuned-sst-2-english\", \"Detect emotional tone.\"),\n",
    "    \"Zero-Shot Classification\": (\"facebook/bart-large-mnli\", \"Classify without training labels.\"),\n",
    "    \"Question Answering\": (\"deepset/roberta-base-squad2\", \"Extract factual answers from context.\"),\n",
    "    \"NER\": (\"dslim/bert-base-NER\", \"Identify names, places, organizations.\"),\n",
    "    \"Text Generation\": (\"google/flan-t5-base\", \"Generate or reason in natural language.\"),\n",
    "}\n",
    "\n",
    "Markdown(\"### ğŸ“‹ Common Model Choices\\n\" + \n",
    "          \"\\n\".join([f\"- **{k}** â†’ `{v[0]}`  â€”  _{v[1]}_\" for k, v in models.items()]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Agent Selector\n",
    "Students can experiment: enter a task description, and the notebook will recommend a pipeline and agent type.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Recommended Agent Type: General Research Agent\n",
      "Suggested Model: facebook/bart-large-cnn\n"
     ]
    }
   ],
   "source": [
    "def choose_agent(task: str):\n",
    "    task = task.lower()\n",
    "    if any(word in task for word in [\"summarize\", \"overview\", \"explain\", \"report\"]):\n",
    "        return \"Retrieval Agent\", \"facebook/bart-large-cnn\"\n",
    "    elif any(word in task for word in [\"sentiment\", \"tone\", \"opinion\", \"positive\"]):\n",
    "        return \"Analyst Agent\", \"distilbert/distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "    elif any(word in task for word in [\"classify\", \"intent\", \"category\"]):\n",
    "        return \"Support Agent\", \"facebook/bart-large-mnli\"\n",
    "    elif any(word in task for word in [\"verify\", \"true\", \"check\", \"fact\"]):\n",
    "        return \"Fact-Checker Agent\", \"deepset/roberta-base-squad2\"\n",
    "    elif any(word in task for word in [\"recommend\", \"decide\", \"choose\"]):\n",
    "        return \"Decision Agent\", \"google/flan-t5-base\"\n",
    "    else:\n",
    "        return \"General Research Agent\", \"facebook/bart-large-cnn\"\n",
    "\n",
    "task = input(\"Describe your NLP task (e.g., 'Analyze tone of AI headlines'): \")\n",
    "agent, model = choose_agent(task)\n",
    "\n",
    "print(f\"\\n Recommended Agent Type: {agent}\")\n",
    "print(f\"Suggested Model: {model}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Test Cell â€” Run Your Chosen Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/swatichandna/.pyenv/versions/3.11.7/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading text2text-generation pipeline with model: facebook/bart-large-cnn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Output:\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery. Please submit\n",
      "your best shots of the U.S. for next week. Visit CNN.com/Travel next Wednesday for a new\n",
      "gallery of snapshots. Please share your best photos of the United States with\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import textwrap\n",
    "\n",
    "text = input(\"\\nEnter text or a question to test your agent: \")\n",
    "\n",
    "chosen_model = model  # from previous cell\n",
    "if \"summarize\" in agent.lower():\n",
    "    task_type = \"summarization\"\n",
    "elif \"analyst\" in agent.lower() or \"sentiment\" in task.lower():\n",
    "    task_type = \"sentiment-analysis\"\n",
    "elif \"support\" in agent.lower():\n",
    "    task_type = \"zero-shot-classification\"\n",
    "elif \"fact\" in agent.lower():\n",
    "    task_type = \"question-answering\"\n",
    "else:\n",
    "    task_type = \"text2text-generation\"\n",
    "\n",
    "try:\n",
    "    print(f\"\\nLoading {task_type} pipeline with model: {chosen_model}\")\n",
    "    pipe = pipeline(task_type, model=chosen_model)\n",
    "    if task_type == \"summarization\":\n",
    "        out = pipe(text, max_length=120, min_length=40, do_sample=False)[0][\"summary_text\"]\n",
    "    elif task_type == \"sentiment-analysis\":\n",
    "        out = pipe(text)[0]\n",
    "        out = f\"Label: {out['label']}, Score: {out['score']:.2f}\"\n",
    "    elif task_type == \"zero-shot-classification\":\n",
    "        labels = [\"complaint\", \"refund request\", \"question\", \"praise\"]\n",
    "        out = pipe(text, candidate_labels=labels)\n",
    "        out = f\"Predicted label: {out['labels'][0]}, Confidence: {out['scores'][0]:.2f}\"\n",
    "    elif task_type == \"question-answering\":\n",
    "        context = \"Germany generated 55% of its electricity from renewable sources in 2023.\"\n",
    "        out = pipe(question=text, context=context)\n",
    "        out = f\"Answer: {out['answer']} (score: {out['score']:.2f})\"\n",
    "    else:\n",
    "        out = pipe(text, max_length=60)[0][\"generated_text\"]\n",
    "\n",
    "    print(\"\\nModel Output:\")\n",
    "    print(\"â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\")\n",
    "    print(textwrap.fill(str(out), width=90))\n",
    "except Exception as e:\n",
    "    print(\"Error:\", e)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
