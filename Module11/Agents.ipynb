{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Information-Seeking Agent (Mini Research Assistant)\n",
    "\n",
    "**Goal:**  \n",
    "Create an agent that searches the web and summarizes its findings.  \n",
    "*(Shows: retrieval + summarization pipeline)*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Topic Selected: Renewable energy in Germany\n",
      "──────────────────────────────────────────────\n",
      " Retrieved Context:\n",
      "Renewable energy in Germany is mainly based on wind, solar and biomass.  In 2024, 59,0 % (254,9 TWh\n",
      "of 431,7 TWh) of the electricity produced in Germany came from renewable Energies:  31,87 %   Wind\n",
      "(Onshore 25,92 % + offshore 5,95 %), Photovoltaics 14,66, Biomass 8,33 %, hydropower 3,97 %. Germany\n",
      "had the world's largest photovoltaic installed capacity until 2014, and as of 2023 it had over 82\n",
      "GW. In 2021, it was the world's third country by installed total wind power capacity, 64 GW in 2021\n",
      "and second for offshore wind, with over 7 GW. In 2009, Germany was called \"the world's first major\n",
      "renewable energy economy\". The share of renewable energy in electricity production increased from\n",
      "3.5%\n",
      "...\n",
      "\n",
      " Agent Summary:\n",
      "──────────────────────────────────────────────\n",
      "In 2024, 59,0 % (254,9 TWh of 431,7 TWh) of the electricity produced in Germany came from renewable\n",
      "Energies. Renewable energy in Germany is mainly based on wind, solar and biomass. In 2009, Germany\n",
      "was called \"the world's first major renewable energy economy\"\n"
     ]
    }
   ],
   "source": [
    "# Information-Seeking Agent — Clean, Formatted Output Version\n",
    "# ---------------------------------------------------------------\n",
    "# pip install wikipedia transformers torch --quiet\n",
    "\n",
    "import wikipedia\n",
    "from transformers import pipeline\n",
    "import textwrap\n",
    "\n",
    "# Initialize summarizer\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "\n",
    "# Step 1: Define the topic\n",
    "topic = \"Renewable energy in Germany\"\n",
    "\n",
    "print(\" Topic Selected:\", topic)\n",
    "print(\"──────────────────────────────────────────────\")\n",
    "\n",
    "# Step 2: Retrieve information from Wikipedia\n",
    "raw_text = wikipedia.summary(topic, sentences=10)\n",
    "\n",
    "print(\" Retrieved Context:\")\n",
    "print(textwrap.fill(raw_text[:700], width=100))\n",
    "print(\"...\")\n",
    "\n",
    "# Step 3: Summarize the retrieved content\n",
    "summary = summarizer(raw_text, max_length=120, min_length=40, do_sample=False)[0][\"summary_text\"]\n",
    "\n",
    "print(\"\\n Agent Summary:\")\n",
    "print(\"──────────────────────────────────────────────\")\n",
    "print(textwrap.fill(summary, width=100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 — News Analyst Agent\n",
    "\n",
    "**Goal:**  \n",
    "Retrieve current news and analyze the *sentiment* of what it finds.  \n",
    "*(Shows: retrieval + evaluation pipeline)*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " AGENT QUERY:\n",
      "──────────────────────────────────────────────\n",
      "latest AI regulation news 2024 site:bbc.com OR site:reuters.com\n",
      "──────────────────────────────────────────────\n",
      "\n",
      "RETRIEVED HEADLINES:\n",
      "──────────────────────────────────────────────\n",
      "1. EU sticks with timeline for AI rules | Reuters. The European Union's landmark rules on\n",
      "artificial intelligence will be rolled out according to the leg\n",
      "\n",
      "2. AI News | Latest Headlines and Developments | Reuters. Explore the latest artificial\n",
      "intelligence news with Reuters - from AI breakthroughs and techno\n",
      "\n",
      "3. US senators call for Meta probe after Reuters report on its AI policies. Two Republican\n",
      "U.S. senators called for a congressional investigation into Me\n",
      "\n",
      " SENTIMENT SUMMARY:\n",
      "──────────────────────────────────────────────\n",
      "NEGATIVE   → confidence 0.95\n"
     ]
    }
   ],
   "source": [
    "# pip install ddgs transformers torch --quiet\n",
    "\n",
    "from ddgs import DDGS\n",
    "from transformers import pipeline\n",
    "import textwrap\n",
    "\n",
    "# Step 1: Initialize sentiment pipeline\n",
    "sentiment = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=\"distilbert/distilbert-base-uncased-finetuned-sst-2-english\"\n",
    ")\n",
    "\n",
    "# Step 2: Define query\n",
    "query = \"latest AI regulation news 2024 site:bbc.com OR site:reuters.com\"\n",
    "\n",
    "print(\" AGENT QUERY:\")\n",
    "print(\"──────────────────────────────────────────────\")\n",
    "print(textwrap.fill(query, width=90))\n",
    "print(\"──────────────────────────────────────────────\\n\")\n",
    "\n",
    "# Step 3: Search recent news using DuckDuckGo / DDGS\n",
    "with DDGS() as ddgs:\n",
    "    results = [r[\"title\"] + \". \" + r[\"body\"] for r in ddgs.text(query, max_results=3)]\n",
    "\n",
    "# Combine results into context\n",
    "context = \" \".join(results)\n",
    "\n",
    "# Display retrieved headlines\n",
    "print(\"RETRIEVED HEADLINES:\")\n",
    "print(\"──────────────────────────────────────────────\")\n",
    "if results:\n",
    "    for i, res in enumerate(results, 1):\n",
    "        print(f\"{i}. {textwrap.fill(res[:150], width=90)}\\n\")\n",
    "else:\n",
    "    print(\" No results found. Try another query or site filter.\\n\")\n",
    "\n",
    "# Step 4: Analyze sentiment of combined text\n",
    "analysis = sentiment(context[:512])\n",
    "print(\" SENTIMENT SUMMARY:\")\n",
    "print(\"──────────────────────────────────────────────\")\n",
    "for a in analysis:\n",
    "    label = a[\"label\"]\n",
    "    score = a[\"score\"]\n",
    "    print(f\"{label:<10} → confidence {score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer Support Agent\n",
    "\n",
    "**Goal:**  \n",
    "Detect user intent and decide on an action.  \n",
    "*(Shows: perception → decision → action loop)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUSTOMER MESSAGE:\n",
      "──────────────────────────────────────────────\n",
      "My package hasn't arrived even after 10 days and no one is replying to my emails!\n",
      "──────────────────────────────────────────────\n",
      "\n",
      "DETECTED INTENT:\n",
      "──────────────────────────────────────────────\n",
      "COMPLAINT  →  confidence 0.80\n",
      "\n",
      "AGENT DECISION:\n",
      "──────────────────────────────────────────────\n",
      "We’re sorry for the delay. I’ll create a priority support ticket and update you within 24\n",
      "hours. Thank you for your patience!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# pip install transformers torch --quiet\n",
    "\n",
    "from transformers import pipeline\n",
    "import textwrap\n",
    "\n",
    "# Step 1 – Initialize zero-shot classifier\n",
    "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "\n",
    "# Step 2 – Define the incoming message\n",
    "customer_message = \"My package hasn't arrived even after 10 days and no one is replying to my emails!\"\n",
    "\n",
    "print(\"CUSTOMER MESSAGE:\")\n",
    "print(\"──────────────────────────────────────────────\")\n",
    "print(textwrap.fill(customer_message, width=90))\n",
    "print(\"──────────────────────────────────────────────\\n\")\n",
    "\n",
    "# Step 3 – Classify intent\n",
    "candidate_labels = [\"complaint\", \"refund request\", \"greeting\", \"product inquiry\", \"technical issue\"]\n",
    "prediction = classifier(customer_message, candidate_labels=candidate_labels)\n",
    "intent = prediction[\"labels\"][0]\n",
    "confidence = prediction[\"scores\"][0]\n",
    "\n",
    "print(\"DETECTED INTENT:\")\n",
    "print(\"──────────────────────────────────────────────\")\n",
    "print(f\"{intent.upper()}  →  confidence {confidence:.2f}\\n\")\n",
    "\n",
    "# Step 4 – Decide an appropriate action\n",
    "print(\"AGENT DECISION:\")\n",
    "print(\"──────────────────────────────────────────────\")\n",
    "if intent in [\"complaint\", \"refund request\"]:\n",
    "    response = (\n",
    "        \"We’re sorry for the delay. I’ll create a priority support ticket and \"\n",
    "        \"update you within 24 hours. Thank you for your patience!\"\n",
    "    )\n",
    "elif intent == \"technical issue\":\n",
    "    response = (\n",
    "        \"Please describe the issue in detail and we’ll connect you with a \"\n",
    "        \"technical specialist right away.\"\n",
    "    )\n",
    "elif intent == \"greeting\":\n",
    "    response = \"Hello! How can I assist you today?\"\n",
    "else:\n",
    "    response = (\n",
    "        \"I’d be happy to provide product information or track your order. \"\n",
    "        \"Could you share your order ID?\"\n",
    "    )\n",
    "\n",
    "print(textwrap.fill(response, width=90))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Design Your Own Mini Agent\n",
    "**Goal:**  \n",
    "Apply what you learned about agents (reasoning, tool use, reflection) to build your own small task-oriented agent.  \n",
    "This could be:\n",
    "- a **news sentiment agent**,  \n",
    "- a **product recommendation agent**, or  \n",
    "- a **fact-checking agent**.\n",
    "\n",
    "**You will:**\n",
    "1. Define your own topic or problem.  \n",
    "2. Retrieve text from the web (using DDGS or Wikipedia).  \n",
    "3. Analyze or reason about that text using an LLM pipeline.  \n",
    "4. Print your findings in a readable, agentic format.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Choose agent type: (1) Research summarizer  (2) Sentiment analyzer  (3) Fact-checker\n",
      "\n",
      " AGENT QUERY:\n",
      "──────────────────────────────────────────────\n",
      "summary site:bbc.com OR site:reuters.com\n",
      "──────────────────────────────────────────────\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/36/c6m7q9gx4njbdgdy1y3mj9gm0000gn/T/ipykernel_24537/2079546550.py:24: ResourceWarning: unclosed <ssl.SSLSocket fd=96, family=2, type=1, proto=0, laddr=('192.168.178.96', 59516), raddr=('40.114.177.156', 443)>\n",
      "  with DDGS() as ddgs:\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RETRIEVED CONTEXT:\n",
      "──────────────────────────────────────────────\n",
      "Reuters | Breaking International News & Views. Find latest news from every corner of the\n",
      "globe at Reuters.com , your online source for breaking international news coverage. Global\n",
      "Market Headlines | Breaking Stock Market News | Reuters. Find the latest stock market news\n",
      "from every corner of the globe at Reuters.com , your online source for breaking\n",
      "international market and finance news US economy at risk of wobble as lower-income\n",
      "consumers get squeezed. The U.S. consumer's durability as a prop f\n",
      "...\n",
      " Invalid choice. Please rerun and select 1, 2, or 3.\n"
     ]
    }
   ],
   "source": [
    "# pip install ddgs transformers torch wikipedia --quiet\n",
    "\n",
    "from ddgs import DDGS\n",
    "from transformers import pipeline\n",
    "import textwrap, wikipedia\n",
    "\n",
    "# Choose your own topic\n",
    "topic = input(\"Enter your agent’s topic or task (e.g., 'AI in education 2024'): \")\n",
    "\n",
    "#  Choose the agent type\n",
    "print(\"\\nChoose agent type: (1) Research summarizer  (2) Sentiment analyzer  (3) Fact-checker\")\n",
    "choice = input(\"Enter 1, 2, or 3: \")\n",
    "\n",
    "print(\"\\n AGENT QUERY:\")\n",
    "print(\"──────────────────────────────────────────────\")\n",
    "query = f\"{topic} site:bbc.com OR site:reuters.com\"\n",
    "print(textwrap.fill(query, width=90))\n",
    "print(\"──────────────────────────────────────────────\\n\")\n",
    "\n",
    "#  Retrieve text (students can modify)\n",
    "context = \"\"\n",
    "with DDGS() as ddgs:\n",
    "    results = [r[\"title\"] + \". \" + r[\"body\"] for r in ddgs.text(query, max_results=3)]\n",
    "    context = \" \".join(results)\n",
    "\n",
    "if not context:\n",
    "    print(\"No search results found. Trying Wikipedia instead.\")\n",
    "    try:\n",
    "        context = wikipedia.summary(topic, sentences=5)\n",
    "    except:\n",
    "        print(\"⚠️ Wikipedia also has no entry for this topic.\")\n",
    "        context = \"\"\n",
    "\n",
    "print(\"RETRIEVED CONTEXT:\")\n",
    "print(\"──────────────────────────────────────────────\")\n",
    "print(textwrap.fill(context[:500], width=90))\n",
    "print(\"...\")\n",
    "\n",
    "#  Based on agent type — students fill in logic\n",
    "if choice == \"1\":\n",
    "    print(\"\\n TASK: Summarize the retrieved text\\n\")\n",
    "    summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "    summary = summarizer(context[:2000], max_length=120, min_length=40, do_sample=False)[0][\"summary_text\"]\n",
    "    print(\"SUMMARY RESULT:\")\n",
    "    print(\"──────────────────────────────────────────────\")\n",
    "    print(textwrap.fill(summary, width=90))\n",
    "\n",
    "elif choice == \"2\":\n",
    "    print(\"\\n TASK: Sentiment analysis of retrieved text\\n\")\n",
    "    sentiment = pipeline(\"sentiment-analysis\")\n",
    "    analysis = sentiment(context[:512])\n",
    "    print(\"SENTIMENT RESULT:\")\n",
    "    print(\"──────────────────────────────────────────────\")\n",
    "    for a in analysis:\n",
    "        label = a[\"label\"]\n",
    "        score = a[\"score\"]\n",
    "        print(f\" {label:<10} → confidence {score:.2f}\")\n",
    "\n",
    "elif choice == \"3\":\n",
    "    print(\"\\nTASK: Fact-check the main claim (students implement their logic)\\n\")\n",
    "    print(\"# Optional: use a question-answering pipeline here\")\n",
    "    print(\"# Example:\")\n",
    "    print(\"# qa = pipeline('question-answering', model='deepset/roberta-base-squad2')\")\n",
    "    print(\"# claim = input('Enter a claim to verify: ')\")\n",
    "    print(\"# answer = qa(question=claim, context=context)\")\n",
    "    print(\"# print(' Agent conclusion:', answer['answer'])\")\n",
    "else:\n",
    "    print(\" Invalid choice. Please rerun and select 1, 2, or 3.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
