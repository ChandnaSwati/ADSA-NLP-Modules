{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 1 — Exploring FAISS (Local Vector Search)\n",
    "\n",
    "### Goal:\n",
    "\n",
    "Understand how to store, index, and retrieve document embeddings locally using FAISS.\n",
    "\n",
    "### Tasks:\n",
    "- Install faiss-cpu and sentence-transformers.\n",
    "- Create a mini-corpus (10–20 short texts on a topic like “AI for environment”).\n",
    "- Generate embeddings using SentenceTransformer(\"all-MiniLM-L6-v2\").\n",
    "- Store them in a FAISS index (IndexFlatL2).\n",
    "- Search for the top-k most similar documents for a given query.\n",
    "- Plot similarity distances (e.g., bar chart or cosine heatmap).\n",
    "\n",
    "### Reflection:\n",
    "- How does L2 distance differ from cosine similarity?\n",
    "- How would results change if you normalize embeddings?\n",
    "\n",
    "### Deliverables:\n",
    "-.ipynb notebook with code + explanation\n",
    "- Short paragraph describing insights (semantic vs keyword retrieval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 2 — Building a Mini Knowledge Base with Chroma\n",
    "\n",
    "### Goal:\n",
    "\n",
    "Learn to build a simple local vector database using Chroma, integrated with embeddings and LangChain.\n",
    "\n",
    "### Tasks:\n",
    "- Install chromadb and sentence-transformers.\n",
    "- Create a collection in Chroma called \"ai_water_docs\".\n",
    "- Add at least 10 documents with text + metadata (e.g., title, source).\n",
    "- Query the collection with 3 different questions (e.g., “How does AI detect pollution?”).\n",
    "- Visualize which documents are retrieved (e.g., top 3).\n",
    "- Optional: integrate with LangChain for a small RAG-style Q&A.\n",
    "\n",
    "### Reflection:\n",
    "- What happens if you add the same text twice — does Chroma deduplicate?\n",
    "- How can you filter by metadata (e.g., only “scientific” docs)?\n",
    "\n",
    "### Deliverables:\n",
    "- Working notebook or Python script\n",
    "- Screenshot of retrieved results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 3 — Using Pinecone (Cloud Vector Database)\n",
    "\n",
    "### Goal:\n",
    "\n",
    "Deploy a scalable, cloud-based vector database using Pinecone, and compare results to FAISS.\n",
    "\n",
    "### Tasks:\n",
    "- Create a free Pinecone account → get API key.\n",
    "- Install the client: pip install pinecone-client.\n",
    "- Initialize Pinecone and create an index called \"student-demo\".\n",
    "- Insert at least 50 documents + embeddings.\n",
    "- Write code to query Pinecone for semantic matches.\n",
    "- Compare the top-3 retrieved results with your FAISS results for the same query.\n",
    "\n",
    "### Reflection:\n",
    "- How does latency compare to FAISS (local)?\n",
    "- What advantages does a managed vector DB provide?\n",
    "\n",
    "### Deliverables:\n",
    "- Notebook + screenshots of results\n",
    "- Comparison table (FAISS vs Pinecone: speed, setup, ease)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus / Advanced Assignments (Optional)\n",
    "\n",
    "## Bonus 1 — Hybrid Search with Weaviate\n",
    "Combine BM25 + vector search in one system.\n",
    "\n",
    "Tasks:\n",
    "1. Launch Weaviate (Docker or Cloud)\n",
    "2. Insert sample texts into a \"ResearchDoc\" class\n",
    "3. Run nearText (semantic) vs bm25 (keyword) queries\n",
    "4. Compare which retrieves better answers\n",
    "\n",
    "\n",
    "## Bonus 2 — Scalable Indexing with Milvus\n",
    "Explore large-scale and ANN indexing performance.\n",
    "\n",
    "Tasks:\n",
    "1. Run Milvus locally or use Zilliz Cloud\n",
    "2. Insert ~1 000 vectors into a collection\n",
    "3. Build IVF or HNSW index\n",
    "4. Measure query speed before/after indexing\n",
    "\n",
    "## Bonus 3 — Metadata Filtering with Qdrant\n",
    "Experiment with filtered semantic queries.\n",
    "\n",
    "Tasks:\n",
    "1. Run Qdrant (Docker or in-memory)\n",
    "2. Insert 20 vectors + metadata (year, source)\n",
    "3. Query semantically + apply filters (e.g., year > 2021)\n",
    "4. Compare results with and without filters"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
